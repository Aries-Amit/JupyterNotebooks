{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4f8882ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from OPENAI_KEY import secret_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fe04a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "\n",
    "os.environ['OPENAI_API_KEY'] = secret_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f657288",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "\n",
    "llm = OpenAI(temperature = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac7019ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = llm('I want to open a restaurent. Suggest a fancy name for that.')\n",
    "\n",
    "print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd836f1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I want to open a Mexican restaurent. Suggest a fancy name for that.'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "prompt_template_name = PromptTemplate(\n",
    "    input_variables = ['cuisine'],\n",
    "    template = \"I want to open a {cuisine} restaurent. Suggest a fancy name for that.\"\n",
    ")\n",
    "\n",
    "prompt_template_name.format(cuisine = \"Mexican\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb7e483",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = LLMChain(llm = llm,\n",
    "                 prompt = prompt_template_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1356d41f",
   "metadata": {},
   "source": [
    "# LangChain OpenAI API main code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981b35b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing frameworks\n",
    "\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SimpleSequentialChain\n",
    "\n",
    "from OPENAI_KEY import secret_key\n",
    "import os\n",
    "\n",
    "os.environ['OPEN_API_KEY'] = secret_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9870dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating model\n",
    "llm = OpenAI(tempertaure = 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "29e7f3d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating prompt for the restaurent name\n",
    "prompt_restaurent_name = PromptTemplate(\n",
    "                        input_variables = ['cuisine'],\n",
    "                        template = \"I want to open a restaurent for {cuisine} food. Suggest a fancy name for that.\"    \n",
    ")\n",
    "\n",
    "# creating chain for the first prompt\n",
    "name_chain = LLMChain(llm = llm,\n",
    "                     prompt = prompt_restaurent_name)\n",
    "\n",
    "# creating prompt for the menu items\n",
    "prompt_menu_items = PromptTemplate(\n",
    "                        input_variables = ['restaurent_name'],\n",
    "                        template = \"Suggest the menu items for {restaurent_name}. Return it as a comma seperated list.\"\n",
    ")\n",
    "\n",
    "menu_chain = LLMChain(llm = llm,\n",
    "                     prompt = prompt_menu_items) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f09266",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple sequential chain that will print only menu item\n",
    "\n",
    "chain = SimpleSequentialChain(chain = [name_chain, menu_chain])\n",
    "\n",
    "response = chain.run('Mexican')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc190ce6",
   "metadata": {},
   "source": [
    "# Final code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "aab656c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import SequentialChain\n",
    "\n",
    "from OPENAI_KEY import secret_key\n",
    "import os\n",
    "\n",
    "os.environ['OPEN_API_KEY'] = secret_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "441c4792",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature = 0.7)\n",
    "\n",
    "prompt_rname = PromptTemplate(\n",
    "                    input_variables = ['cuisine'],\n",
    "                    template = \"I want to open a restaurent for {cuisine} food. Suggest a fancy name for that.\"\n",
    ")\n",
    "\n",
    "chain_rname = LLMChain(llm = llm, prompt = prompt_rname, output_key = 'restaurent_name')\n",
    "\n",
    "llm = OpenAI(temperature = 0.7)\n",
    "\n",
    "prompt_items = PromptTemplate(\n",
    "                    input_variables = ['restaurent_name'],\n",
    "                    template = \"Suggest the menu items for {restaurent_name}. Return it as a comma seperated list.\"\n",
    ")\n",
    "\n",
    "chain_items = LLMChain(llm = llm, prompt = prompt_items, output_key = 'menu_items')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f09e37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = SequentialChain(chain = [chain_rname, chain_items],\n",
    "                       input_variables = 'cuisine',\n",
    "                       output_variables = ['restaurent_name', 'menu_items'])\n",
    "\n",
    "chain({'cuisine' : 'Indian'})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
